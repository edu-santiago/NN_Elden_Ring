{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c283d9d2-c2c7-4916-9125-92819488274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import re\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.pre_processing import *\n",
    "from utils.nn import *\n",
    "from utils.nn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d24a86e7-bab3-416a-9115-98645a368e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('data/df_tags','data/final_reviews')\n",
    "X_train, X_test, X_val, y_val, y_train, y_test = init_df(df,test_size=0.2,target_col='target',stratify=True,scaling=True,oversampling=True)\n",
    "X_train, X_test, X_val, to_remove = remove_highly_correlated_features(X_train, X_test, X_val, threshold=0.9)\n",
    "df = df.drop(columns=df.columns[to_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "209c0e99-2473-40aa-a390-6e08b15dd1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2705, number of negative: 2705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 75579\n",
      "[LightGBM] [Info] Number of data points in the train set: 5410, number of used features: 304\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.8263305322128851\n",
      "Precision: 0.1\n",
      "Recall: 0.17307692307692307\n",
      "F1 Score: 0.1267605633802817\n"
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]  # Assuming the last column is the target\n",
    "\n",
    "# Create LightGBM datasets\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train, feature_name=list(feature_names))\n",
    "lgb_val = lgb.Dataset(X_val, label=y_val, feature_name=list(feature_names), reference=lgb_train)\n",
    "\n",
    "# Define the model parameters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 1\n",
    "}\n",
    "\n",
    "def f1_eval(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    y_pred_binary = np.round(y_pred)\n",
    "    return 'f1', f1_score(y_true, y_pred_binary), True\n",
    "\n",
    "# Train the model\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    lgb_train, \n",
    "    num_boost_round=100, \n",
    "    valid_sets=[lgb_train, lgb_val], \n",
    "    valid_names=['train', 'val'],\n",
    "    feval=f1_eval\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "y_val_pred_binary = np.round(y_val_pred)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "precision = precision_score(y_val, y_val_pred_binary)\n",
    "recall = recall_score(y_val, y_val_pred_binary)\n",
    "f1 = f1_score(y_val, y_val_pred_binary)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Get feature importance\n",
    "importance = model.feature_importance()\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Return the feature importance and metrics\n",
    "evaluation_metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1\n",
    "}\n",
    "\n",
    "quantile_to_keep = 0.5\n",
    "min_imp = feature_importance['Importance'].quantile(quantile_to_keep)\n",
    "imp_feats = feature_importance.loc[feature_importance['Importance'] >= min_imp]['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3423ad25-5846-49c2-82ef-08c04acedb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254                        Werewolves\n",
       "290                      Outbreak Sim\n",
       "289    Intentionally Awkward Controls\n",
       "56                     Hack and Slash\n",
       "287                       Programming\n",
       "286                     Warhammer 40K\n",
       "57                             Nudity\n",
       "278                             Party\n",
       "293                         Benchmark\n",
       "283                       Time Attack\n",
       "282                       Agriculture\n",
       "280                 Time Manipulation\n",
       "63                   Great Soundtrack\n",
       "294                     Political Sim\n",
       "82                       Early Access\n",
       "205                        Minimalist\n",
       "258                      Auto Battler\n",
       "259          Asynchronous Multiplayer\n",
       "35                             Aliens\n",
       "285                             Naval\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort_values('Importance')['Feature'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c0331db-f753-4a98-8b30-3968f49d2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('data/df_tags','data/final_reviews')\n",
    "\n",
    "X_train, X_test, y_train, y_test = init_df(df,test_size=0.2,target_col='target',stratify=True,scaling=False,oversampling=False,val=False)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "X_train_reduced = np.delete(X_train, to_remove, axis=1)\n",
    "X_test_reduced = np.delete(X_test, to_remove, axis=1)\n",
    "\n",
    "reduced_X_train = X_train[:, imp_feats.index]\n",
    "reduced_X_test = X_test[:, imp_feats.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d70e258-8401-465c-926f-f9cb476ba5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3569, 166)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c77761ec-20ef-43ce-ba8b-699c2f49b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constantes\n",
    "\n",
    "input_size = reduced_X_train.shape[1]\n",
    "output_size = 1\n",
    "num_epochs = 1000\n",
    "hidden_activation = 'relu'\n",
    "output_activation='sigmoid'\n",
    "criterion = 'BCEWithLogitsLoss'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb099370-bfb5-4632-b390-738e9ee76585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7e396736764081ab25a651ea0fde81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Accuracy: 0.5647058823529412\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.002583979328165375\n",
      "F1: 0.005121638924455826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076f8242c9ca4698bd06e46601a407c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.566 | Val Loss: 0.7032 | Train F1: 0.8395| Val F1: 0.0535\n",
      "Epoch 100: | Train Loss: 0.543 | Val Loss: 0.6983 | Train F1: 0.8881| Val F1: 0.0564\n",
      "Epoch 150: | Train Loss: 0.535 | Val Loss: 0.6965 | Train F1: 0.8922| Val F1: 0.0494\n",
      "Early stopping at epoch 173\n",
      "Accuracy: 0.569187675070028\n",
      "Precision: 0.5675675675675675\n",
      "Recall: 0.027131782945736434\n",
      "F1: 0.051787916152897656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ab7aad1dae453382d87774066acac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.665 | Val Loss: 0.7217 | Train F1: 0.3957| Val F1: 0.0441\n",
      "Epoch 100: | Train Loss: 0.640 | Val Loss: 0.7136 | Train F1: 0.5071| Val F1: 0.0508\n",
      "Epoch 150: | Train Loss: 0.622 | Val Loss: 0.7114 | Train F1: 0.6075| Val F1: 0.0483\n",
      "Epoch 200: | Train Loss: 0.607 | Val Loss: 0.7104 | Train F1: 0.6848| Val F1: 0.0457\n",
      "Epoch 250: | Train Loss: 0.594 | Val Loss: 0.7093 | Train F1: 0.7387| Val F1: 0.0595\n",
      "Epoch 300: | Train Loss: 0.584 | Val Loss: 0.7080 | Train F1: 0.7592| Val F1: 0.0644\n",
      "Epoch 350: | Train Loss: 0.575 | Val Loss: 0.7065 | Train F1: 0.7931| Val F1: 0.0600\n",
      "Epoch 400: | Train Loss: 0.568 | Val Loss: 0.7050 | Train F1: 0.7970| Val F1: 0.0671\n",
      "Epoch 450: | Train Loss: 0.562 | Val Loss: 0.7038 | Train F1: 0.8255| Val F1: 0.0602\n",
      "Epoch 500: | Train Loss: 0.557 | Val Loss: 0.7029 | Train F1: 0.8371| Val F1: 0.0696\n",
      "Epoch 550: | Train Loss: 0.554 | Val Loss: 0.7022 | Train F1: 0.8398| Val F1: 0.0651\n",
      "Epoch 600: | Train Loss: 0.550 | Val Loss: 0.7014 | Train F1: 0.8478| Val F1: 0.0630\n",
      "Epoch 650: | Train Loss: 0.547 | Val Loss: 0.7008 | Train F1: 0.8435| Val F1: 0.0631\n",
      "Early stopping at epoch 690\n",
      "Accuracy: 0.5669467787114846\n",
      "Precision: 0.5111111111111111\n",
      "Recall: 0.029715762273901807\n",
      "F1: 0.05616605616605617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ede3598c9f048e38ab55eaa15ecb2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.707 | Val Loss: 0.7500 | Train F1: 0.3384| Val F1: 0.2402\n",
      "Epoch 100: | Train Loss: 0.700 | Val Loss: 0.7439 | Train F1: 0.3204| Val F1: 0.1211\n",
      "Epoch 150: | Train Loss: 0.693 | Val Loss: 0.7390 | Train F1: 0.3488| Val F1: 0.0848\n",
      "Epoch 200: | Train Loss: 0.688 | Val Loss: 0.7350 | Train F1: 0.3526| Val F1: 0.0740\n",
      "Epoch 250: | Train Loss: 0.684 | Val Loss: 0.7317 | Train F1: 0.3455| Val F1: 0.0606\n",
      "Epoch 300: | Train Loss: 0.680 | Val Loss: 0.7289 | Train F1: 0.3582| Val F1: 0.0538\n",
      "Epoch 350: | Train Loss: 0.675 | Val Loss: 0.7265 | Train F1: 0.3606| Val F1: 0.0537\n",
      "Epoch 400: | Train Loss: 0.671 | Val Loss: 0.7244 | Train F1: 0.3895| Val F1: 0.0488\n",
      "Epoch 450: | Train Loss: 0.668 | Val Loss: 0.7226 | Train F1: 0.3983| Val F1: 0.0534\n",
      "Epoch 500: | Train Loss: 0.665 | Val Loss: 0.7210 | Train F1: 0.4246| Val F1: 0.0535\n",
      "Epoch 550: | Train Loss: 0.661 | Val Loss: 0.7196 | Train F1: 0.4289| Val F1: 0.0558\n",
      "Epoch 600: | Train Loss: 0.659 | Val Loss: 0.7184 | Train F1: 0.4314| Val F1: 0.0560\n",
      "Epoch 650: | Train Loss: 0.656 | Val Loss: 0.7173 | Train F1: 0.4481| Val F1: 0.0583\n",
      "Epoch 700: | Train Loss: 0.653 | Val Loss: 0.7164 | Train F1: 0.4499| Val F1: 0.0583\n",
      "Epoch 750: | Train Loss: 0.651 | Val Loss: 0.7155 | Train F1: 0.4546| Val F1: 0.0560\n",
      "Epoch 800: | Train Loss: 0.648 | Val Loss: 0.7148 | Train F1: 0.4861| Val F1: 0.0512\n",
      "Epoch 850: | Train Loss: 0.645 | Val Loss: 0.7142 | Train F1: 0.5221| Val F1: 0.0511\n",
      "Epoch 900: | Train Loss: 0.644 | Val Loss: 0.7137 | Train F1: 0.5169| Val F1: 0.0463\n",
      "Epoch 950: | Train Loss: 0.642 | Val Loss: 0.7132 | Train F1: 0.5291| Val F1: 0.0485\n",
      "Epoch 1000: | Train Loss: 0.639 | Val Loss: 0.7128 | Train F1: 0.5379| Val F1: 0.0509\n",
      "Accuracy: 0.561344537815126\n",
      "Precision: 0.4117647058823529\n",
      "Recall: 0.027131782945736434\n",
      "F1: 0.05090909090909091\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eace6a2da2ee4b31b53da6ce1e212f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Accuracy: 0.5607843137254902\n",
      "Precision: 0.45614035087719296\n",
      "Recall: 0.06718346253229975\n",
      "F1: 0.11711711711711711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a69f191d6d24fcdb5a80fcc404a7d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.586 | Val Loss: 0.7058 | Train F1: 0.7520| Val F1: 0.0691\n",
      "Epoch 100: | Train Loss: 0.555 | Val Loss: 0.7006 | Train F1: 0.8201| Val F1: 0.0585\n",
      "Early stopping at epoch 119\n",
      "Accuracy: 0.5669467787114846\n",
      "Precision: 0.5116279069767442\n",
      "Recall: 0.028423772609819122\n",
      "F1: 0.05385556915544676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968b63ca4f99408e993f4b1bfca6fbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.680 | Val Loss: 0.7307 | Train F1: 0.3840| Val F1: 0.0600\n",
      "Epoch 100: | Train Loss: 0.657 | Val Loss: 0.7191 | Train F1: 0.4449| Val F1: 0.0602\n",
      "Epoch 150: | Train Loss: 0.640 | Val Loss: 0.7140 | Train F1: 0.5329| Val F1: 0.0624\n",
      "Epoch 200: | Train Loss: 0.626 | Val Loss: 0.7119 | Train F1: 0.6136| Val F1: 0.0644\n",
      "Epoch 250: | Train Loss: 0.614 | Val Loss: 0.7107 | Train F1: 0.6383| Val F1: 0.0597\n",
      "Epoch 300: | Train Loss: 0.605 | Val Loss: 0.7095 | Train F1: 0.6945| Val F1: 0.0690\n",
      "Epoch 350: | Train Loss: 0.597 | Val Loss: 0.7086 | Train F1: 0.7301| Val F1: 0.0757\n",
      "Epoch 400: | Train Loss: 0.589 | Val Loss: 0.7075 | Train F1: 0.7471| Val F1: 0.0876\n",
      "Epoch 450: | Train Loss: 0.583 | Val Loss: 0.7066 | Train F1: 0.7660| Val F1: 0.0857\n",
      "Epoch 500: | Train Loss: 0.577 | Val Loss: 0.7055 | Train F1: 0.7784| Val F1: 0.0789\n",
      "Epoch 550: | Train Loss: 0.573 | Val Loss: 0.7047 | Train F1: 0.7800| Val F1: 0.0721\n",
      "Epoch 600: | Train Loss: 0.568 | Val Loss: 0.7038 | Train F1: 0.8011| Val F1: 0.0721\n",
      "Epoch 650: | Train Loss: 0.565 | Val Loss: 0.7030 | Train F1: 0.7910| Val F1: 0.0676\n",
      "Epoch 700: | Train Loss: 0.562 | Val Loss: 0.7023 | Train F1: 0.7952| Val F1: 0.0654\n",
      "Epoch 750: | Train Loss: 0.557 | Val Loss: 0.7016 | Train F1: 0.8185| Val F1: 0.0608\n",
      "Early stopping at epoch 793\n",
      "Accuracy: 0.5686274509803921\n",
      "Precision: 0.5434782608695652\n",
      "Recall: 0.03229974160206718\n",
      "F1: 0.06097560975609756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05b6d26eb6d4597b5ae26a21a6b73f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.708 | Val Loss: 0.7502 | Train F1: 0.2811| Val F1: 0.1994\n",
      "Epoch 100: | Train Loss: 0.704 | Val Loss: 0.7467 | Train F1: 0.2956| Val F1: 0.1140\n",
      "Epoch 150: | Train Loss: 0.699 | Val Loss: 0.7435 | Train F1: 0.2897| Val F1: 0.0819\n",
      "Epoch 200: | Train Loss: 0.695 | Val Loss: 0.7407 | Train F1: 0.3188| Val F1: 0.0602\n",
      "Epoch 250: | Train Loss: 0.692 | Val Loss: 0.7381 | Train F1: 0.3025| Val F1: 0.0554\n",
      "Epoch 300: | Train Loss: 0.688 | Val Loss: 0.7357 | Train F1: 0.3140| Val F1: 0.0489\n",
      "Epoch 350: | Train Loss: 0.685 | Val Loss: 0.7336 | Train F1: 0.3635| Val F1: 0.0466\n",
      "Epoch 400: | Train Loss: 0.682 | Val Loss: 0.7316 | Train F1: 0.3491| Val F1: 0.0466\n",
      "Epoch 450: | Train Loss: 0.679 | Val Loss: 0.7297 | Train F1: 0.3419| Val F1: 0.0466\n",
      "Epoch 500: | Train Loss: 0.677 | Val Loss: 0.7280 | Train F1: 0.3623| Val F1: 0.0466\n",
      "Epoch 550: | Train Loss: 0.674 | Val Loss: 0.7265 | Train F1: 0.3806| Val F1: 0.0466\n",
      "Epoch 600: | Train Loss: 0.672 | Val Loss: 0.7251 | Train F1: 0.3884| Val F1: 0.0442\n",
      "Epoch 650: | Train Loss: 0.669 | Val Loss: 0.7238 | Train F1: 0.4127| Val F1: 0.0418\n",
      "Epoch 700: | Train Loss: 0.665 | Val Loss: 0.7226 | Train F1: 0.4027| Val F1: 0.0442\n",
      "Epoch 750: | Train Loss: 0.664 | Val Loss: 0.7215 | Train F1: 0.3962| Val F1: 0.0466\n",
      "Epoch 800: | Train Loss: 0.661 | Val Loss: 0.7204 | Train F1: 0.4510| Val F1: 0.0513\n",
      "Epoch 850: | Train Loss: 0.660 | Val Loss: 0.7195 | Train F1: 0.4164| Val F1: 0.0512\n",
      "Epoch 900: | Train Loss: 0.657 | Val Loss: 0.7186 | Train F1: 0.4488| Val F1: 0.0511\n",
      "Epoch 950: | Train Loss: 0.657 | Val Loss: 0.7178 | Train F1: 0.4375| Val F1: 0.0512\n",
      "Epoch 1000: | Train Loss: 0.653 | Val Loss: 0.7171 | Train F1: 0.4584| Val F1: 0.0535\n",
      "Accuracy: 0.5641456582633053\n",
      "Precision: 0.4583333333333333\n",
      "Recall: 0.028423772609819122\n",
      "F1: 0.0535279805352798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf816eed1844a4fa0f2f052207ca5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Accuracy: 0.5630252100840336\n",
      "Precision: 0.4605263157894737\n",
      "Recall: 0.04521963824289406\n",
      "F1: 0.08235294117647059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6260f8f103493794f026559e95a1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.606 | Val Loss: 0.7087 | Train F1: 0.6698| Val F1: 0.0909\n",
      "Epoch 100: | Train Loss: 0.573 | Val Loss: 0.7030 | Train F1: 0.7509| Val F1: 0.0743\n",
      "Epoch 150: | Train Loss: 0.559 | Val Loss: 0.6996 | Train F1: 0.7622| Val F1: 0.0745\n",
      "Early stopping at epoch 163\n",
      "Accuracy: 0.569187675070028\n",
      "Precision: 0.5454545454545454\n",
      "Recall: 0.03875968992248062\n",
      "F1: 0.07237635705669482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8487cca1add4efe89f56723769f4a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.686 | Val Loss: 0.7362 | Train F1: 0.3345| Val F1: 0.1146\n",
      "Epoch 100: | Train Loss: 0.667 | Val Loss: 0.7249 | Train F1: 0.4095| Val F1: 0.0816\n",
      "Epoch 150: | Train Loss: 0.652 | Val Loss: 0.7187 | Train F1: 0.4719| Val F1: 0.0822\n",
      "Epoch 200: | Train Loss: 0.641 | Val Loss: 0.7154 | Train F1: 0.5425| Val F1: 0.0820\n",
      "Epoch 250: | Train Loss: 0.631 | Val Loss: 0.7136 | Train F1: 0.5770| Val F1: 0.0841\n",
      "Epoch 300: | Train Loss: 0.624 | Val Loss: 0.7123 | Train F1: 0.5987| Val F1: 0.0887\n",
      "Epoch 350: | Train Loss: 0.615 | Val Loss: 0.7114 | Train F1: 0.6222| Val F1: 0.0819\n",
      "Epoch 400: | Train Loss: 0.610 | Val Loss: 0.7105 | Train F1: 0.6345| Val F1: 0.0819\n",
      "Epoch 450: | Train Loss: 0.603 | Val Loss: 0.7098 | Train F1: 0.6732| Val F1: 0.0842\n",
      "Epoch 500: | Train Loss: 0.597 | Val Loss: 0.7090 | Train F1: 0.6755| Val F1: 0.0840\n",
      "Epoch 550: | Train Loss: 0.594 | Val Loss: 0.7083 | Train F1: 0.6865| Val F1: 0.0888\n",
      "Epoch 600: | Train Loss: 0.588 | Val Loss: 0.7076 | Train F1: 0.7111| Val F1: 0.0933\n",
      "Epoch 650: | Train Loss: 0.585 | Val Loss: 0.7069 | Train F1: 0.7309| Val F1: 0.0935\n",
      "Epoch 700: | Train Loss: 0.582 | Val Loss: 0.7062 | Train F1: 0.7268| Val F1: 0.0869\n",
      "Epoch 750: | Train Loss: 0.578 | Val Loss: 0.7055 | Train F1: 0.7281| Val F1: 0.0848\n",
      "Early stopping at epoch 776\n",
      "Accuracy: 0.5658263305322129\n",
      "Precision: 0.49333333333333335\n",
      "Recall: 0.04780361757105943\n",
      "F1: 0.08716136631330977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3218bb6387442aa05263edc671e5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.714 | Val Loss: 0.7571 | Train F1: 0.3863| Val F1: 0.3945\n",
      "Epoch 100: | Train Loss: 0.710 | Val Loss: 0.7545 | Train F1: 0.3732| Val F1: 0.2978\n",
      "Epoch 150: | Train Loss: 0.707 | Val Loss: 0.7519 | Train F1: 0.3473| Val F1: 0.2586\n",
      "Epoch 200: | Train Loss: 0.705 | Val Loss: 0.7496 | Train F1: 0.3338| Val F1: 0.2193\n",
      "Epoch 250: | Train Loss: 0.701 | Val Loss: 0.7475 | Train F1: 0.3332| Val F1: 0.1837\n",
      "Epoch 300: | Train Loss: 0.699 | Val Loss: 0.7456 | Train F1: 0.3166| Val F1: 0.1696\n",
      "Epoch 350: | Train Loss: 0.697 | Val Loss: 0.7438 | Train F1: 0.3066| Val F1: 0.1358\n",
      "Epoch 400: | Train Loss: 0.695 | Val Loss: 0.7421 | Train F1: 0.3022| Val F1: 0.1230\n",
      "Epoch 450: | Train Loss: 0.692 | Val Loss: 0.7406 | Train F1: 0.3192| Val F1: 0.1163\n",
      "Epoch 500: | Train Loss: 0.690 | Val Loss: 0.7392 | Train F1: 0.3193| Val F1: 0.1039\n",
      "Epoch 550: | Train Loss: 0.688 | Val Loss: 0.7378 | Train F1: 0.3393| Val F1: 0.0931\n",
      "Epoch 600: | Train Loss: 0.686 | Val Loss: 0.7365 | Train F1: 0.3683| Val F1: 0.0886\n",
      "Epoch 650: | Train Loss: 0.684 | Val Loss: 0.7352 | Train F1: 0.3770| Val F1: 0.0843\n",
      "Epoch 700: | Train Loss: 0.682 | Val Loss: 0.7341 | Train F1: 0.3603| Val F1: 0.0821\n",
      "Epoch 750: | Train Loss: 0.680 | Val Loss: 0.7329 | Train F1: 0.3487| Val F1: 0.0775\n",
      "Epoch 800: | Train Loss: 0.679 | Val Loss: 0.7318 | Train F1: 0.3888| Val F1: 0.0773\n",
      "Epoch 850: | Train Loss: 0.677 | Val Loss: 0.7307 | Train F1: 0.3734| Val F1: 0.0730\n",
      "Epoch 900: | Train Loss: 0.674 | Val Loss: 0.7297 | Train F1: 0.3695| Val F1: 0.0734\n",
      "Epoch 950: | Train Loss: 0.673 | Val Loss: 0.7288 | Train F1: 0.4122| Val F1: 0.0756\n",
      "Epoch 1000: | Train Loss: 0.671 | Val Loss: 0.7278 | Train F1: 0.3895| Val F1: 0.0732\n",
      "Accuracy: 0.5602240896358543\n",
      "Precision: 0.4246575342465753\n",
      "Recall: 0.040051679586563305\n",
      "F1: 0.07319952774498228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d4990928ce4f8383093007754b0a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Accuracy: 0.5596638655462185\n",
      "Precision: 0.44339622641509435\n",
      "Recall: 0.060723514211886306\n",
      "F1: 0.10681818181818181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b202ddceaf1417da2736c4ef5b8f98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.625 | Val Loss: 0.7120 | Train F1: 0.5624| Val F1: 0.0947\n",
      "Epoch 100: | Train Loss: 0.595 | Val Loss: 0.7074 | Train F1: 0.6576| Val F1: 0.0864\n",
      "Epoch 150: | Train Loss: 0.581 | Val Loss: 0.7041 | Train F1: 0.6949| Val F1: 0.0621\n",
      "Epoch 200: | Train Loss: 0.568 | Val Loss: 0.7026 | Train F1: 0.7185| Val F1: 0.0481\n",
      "Early stopping at epoch 244\n",
      "Accuracy: 0.5602240896358543\n",
      "Precision: 0.40350877192982454\n",
      "Recall: 0.029715762273901807\n",
      "F1: 0.05535499398315283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd95893886c544dc82482451ba560d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.694 | Val Loss: 0.7406 | Train F1: 0.2923| Val F1: 0.0900\n",
      "Epoch 100: | Train Loss: 0.679 | Val Loss: 0.7318 | Train F1: 0.3347| Val F1: 0.0705\n",
      "Epoch 150: | Train Loss: 0.666 | Val Loss: 0.7251 | Train F1: 0.4072| Val F1: 0.0779\n",
      "Epoch 200: | Train Loss: 0.654 | Val Loss: 0.7207 | Train F1: 0.4526| Val F1: 0.0863\n",
      "Epoch 250: | Train Loss: 0.645 | Val Loss: 0.7177 | Train F1: 0.5214| Val F1: 0.0794\n",
      "Epoch 300: | Train Loss: 0.638 | Val Loss: 0.7158 | Train F1: 0.4890| Val F1: 0.0881\n",
      "Epoch 350: | Train Loss: 0.631 | Val Loss: 0.7145 | Train F1: 0.5571| Val F1: 0.0948\n",
      "Epoch 400: | Train Loss: 0.627 | Val Loss: 0.7133 | Train F1: 0.5594| Val F1: 0.0972\n",
      "Epoch 450: | Train Loss: 0.622 | Val Loss: 0.7124 | Train F1: 0.5629| Val F1: 0.0948\n",
      "Epoch 500: | Train Loss: 0.616 | Val Loss: 0.7117 | Train F1: 0.5992| Val F1: 0.0948\n",
      "Epoch 550: | Train Loss: 0.613 | Val Loss: 0.7112 | Train F1: 0.6000| Val F1: 0.0949\n",
      "Epoch 600: | Train Loss: 0.610 | Val Loss: 0.7105 | Train F1: 0.6279| Val F1: 0.0905\n",
      "Epoch 650: | Train Loss: 0.607 | Val Loss: 0.7098 | Train F1: 0.6088| Val F1: 0.0907\n",
      "Epoch 700: | Train Loss: 0.602 | Val Loss: 0.7091 | Train F1: 0.6519| Val F1: 0.0905\n",
      "Epoch 750: | Train Loss: 0.598 | Val Loss: 0.7086 | Train F1: 0.6628| Val F1: 0.0888\n",
      "Epoch 800: | Train Loss: 0.596 | Val Loss: 0.7081 | Train F1: 0.6706| Val F1: 0.0867\n",
      "Epoch 850: | Train Loss: 0.593 | Val Loss: 0.7076 | Train F1: 0.6824| Val F1: 0.0844\n",
      "Early stopping at epoch 892\n",
      "Accuracy: 0.5607843137254902\n",
      "Precision: 0.4342105263157895\n",
      "Recall: 0.04263565891472868\n",
      "F1: 0.07764705882352942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab71fb8cdc84b3e87de548f5fafacc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.716 | Val Loss: 0.7629 | Train F1: 0.4580| Val F1: 0.5275\n",
      "Epoch 100: | Train Loss: 0.715 | Val Loss: 0.7611 | Train F1: 0.4358| Val F1: 0.4650\n",
      "Epoch 150: | Train Loss: 0.712 | Val Loss: 0.7594 | Train F1: 0.4255| Val F1: 0.4102\n",
      "Epoch 200: | Train Loss: 0.711 | Val Loss: 0.7578 | Train F1: 0.4109| Val F1: 0.3872\n",
      "Epoch 250: | Train Loss: 0.709 | Val Loss: 0.7562 | Train F1: 0.4119| Val F1: 0.3668\n",
      "Epoch 300: | Train Loss: 0.707 | Val Loss: 0.7546 | Train F1: 0.4062| Val F1: 0.3450\n",
      "Epoch 350: | Train Loss: 0.705 | Val Loss: 0.7531 | Train F1: 0.3875| Val F1: 0.3282\n",
      "Epoch 400: | Train Loss: 0.704 | Val Loss: 0.7517 | Train F1: 0.3947| Val F1: 0.3038\n",
      "Epoch 450: | Train Loss: 0.701 | Val Loss: 0.7504 | Train F1: 0.4059| Val F1: 0.2872\n",
      "Epoch 500: | Train Loss: 0.699 | Val Loss: 0.7491 | Train F1: 0.3995| Val F1: 0.2726\n",
      "Epoch 550: | Train Loss: 0.698 | Val Loss: 0.7479 | Train F1: 0.3938| Val F1: 0.2534\n",
      "Epoch 600: | Train Loss: 0.695 | Val Loss: 0.7467 | Train F1: 0.3976| Val F1: 0.2334\n",
      "Epoch 650: | Train Loss: 0.694 | Val Loss: 0.7457 | Train F1: 0.4054| Val F1: 0.2256\n",
      "Epoch 700: | Train Loss: 0.693 | Val Loss: 0.7446 | Train F1: 0.3846| Val F1: 0.2137\n",
      "Epoch 750: | Train Loss: 0.692 | Val Loss: 0.7436 | Train F1: 0.3933| Val F1: 0.2090\n",
      "Epoch 800: | Train Loss: 0.691 | Val Loss: 0.7426 | Train F1: 0.3979| Val F1: 0.1996\n",
      "Epoch 850: | Train Loss: 0.688 | Val Loss: 0.7416 | Train F1: 0.4003| Val F1: 0.1886\n",
      "Epoch 900: | Train Loss: 0.687 | Val Loss: 0.7407 | Train F1: 0.4044| Val F1: 0.1802\n",
      "Epoch 950: | Train Loss: 0.685 | Val Loss: 0.7398 | Train F1: 0.4146| Val F1: 0.1790\n",
      "Epoch 1000: | Train Loss: 0.684 | Val Loss: 0.7390 | Train F1: 0.4181| Val F1: 0.1757\n",
      "Accuracy: 0.5478991596638656\n",
      "Precision: 0.4195121951219512\n",
      "Recall: 0.1111111111111111\n",
      "F1: 0.17568947906026558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea69c8b119ab4b4999b75ffef30bd334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 47\n",
      "Accuracy: 0.5630252100840336\n",
      "Precision: 0.4634146341463415\n",
      "Recall: 0.04909560723514212\n",
      "F1: 0.08878504672897196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20161e78863433d8efae90338dbe988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.641 | Val Loss: 0.7168 | Train F1: 0.4909| Val F1: 0.1333\n",
      "Epoch 100: | Train Loss: 0.618 | Val Loss: 0.7123 | Train F1: 0.5655| Val F1: 0.1424\n",
      "Epoch 150: | Train Loss: 0.607 | Val Loss: 0.7095 | Train F1: 0.5941| Val F1: 0.1329\n",
      "Epoch 200: | Train Loss: 0.597 | Val Loss: 0.7071 | Train F1: 0.6131| Val F1: 0.1320\n",
      "Early stopping at epoch 232\n",
      "Accuracy: 0.565266106442577\n",
      "Precision: 0.49137931034482757\n",
      "Recall: 0.07364341085271318\n",
      "F1: 0.12808988764044943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f446996d8f0c47928a3eb7bac5563a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.709 | Val Loss: 0.7610 | Train F1: 0.5299| Val F1: 0.5676\n",
      "Epoch 100: | Train Loss: 0.699 | Val Loss: 0.7513 | Train F1: 0.4822| Val F1: 0.4168\n",
      "Epoch 150: | Train Loss: 0.688 | Val Loss: 0.7429 | Train F1: 0.4388| Val F1: 0.3103\n",
      "Epoch 200: | Train Loss: 0.678 | Val Loss: 0.7359 | Train F1: 0.4406| Val F1: 0.2490\n",
      "Epoch 250: | Train Loss: 0.672 | Val Loss: 0.7305 | Train F1: 0.4507| Val F1: 0.2200\n",
      "Epoch 300: | Train Loss: 0.666 | Val Loss: 0.7265 | Train F1: 0.4709| Val F1: 0.2027\n",
      "Epoch 350: | Train Loss: 0.658 | Val Loss: 0.7235 | Train F1: 0.4748| Val F1: 0.1830\n",
      "Epoch 400: | Train Loss: 0.652 | Val Loss: 0.7210 | Train F1: 0.4893| Val F1: 0.1709\n",
      "Epoch 450: | Train Loss: 0.648 | Val Loss: 0.7192 | Train F1: 0.4906| Val F1: 0.1640\n",
      "Epoch 500: | Train Loss: 0.646 | Val Loss: 0.7180 | Train F1: 0.5056| Val F1: 0.1602\n",
      "Epoch 550: | Train Loss: 0.640 | Val Loss: 0.7169 | Train F1: 0.5238| Val F1: 0.1603\n",
      "Epoch 600: | Train Loss: 0.637 | Val Loss: 0.7159 | Train F1: 0.5107| Val F1: 0.1518\n",
      "Epoch 650: | Train Loss: 0.633 | Val Loss: 0.7151 | Train F1: 0.5230| Val F1: 0.1522\n",
      "Epoch 700: | Train Loss: 0.630 | Val Loss: 0.7143 | Train F1: 0.5394| Val F1: 0.1508\n",
      "Epoch 750: | Train Loss: 0.628 | Val Loss: 0.7139 | Train F1: 0.5552| Val F1: 0.1533\n",
      "Epoch 800: | Train Loss: 0.623 | Val Loss: 0.7133 | Train F1: 0.5555| Val F1: 0.1468\n",
      "Epoch 850: | Train Loss: 0.620 | Val Loss: 0.7127 | Train F1: 0.5703| Val F1: 0.1452\n",
      "Epoch 900: | Train Loss: 0.618 | Val Loss: 0.7123 | Train F1: 0.5761| Val F1: 0.1477\n",
      "Epoch 950: | Train Loss: 0.619 | Val Loss: 0.7119 | Train F1: 0.5768| Val F1: 0.1392\n",
      "Epoch 1000: | Train Loss: 0.616 | Val Loss: 0.7112 | Train F1: 0.5822| Val F1: 0.1289\n",
      "Accuracy: 0.5607843137254902\n",
      "Precision: 0.4603174603174603\n",
      "Recall: 0.07493540051679587\n",
      "F1: 0.1288888888888889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42fe78210664bc4b4a02db5815452d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.709 | Val Loss: 0.7476 | Train F1: 0.1634| Val F1: 0.0702\n",
      "Epoch 100: | Train Loss: 0.708 | Val Loss: 0.7467 | Train F1: 0.1804| Val F1: 0.0594\n",
      "Epoch 150: | Train Loss: 0.706 | Val Loss: 0.7459 | Train F1: 0.1858| Val F1: 0.0552\n",
      "Epoch 200: | Train Loss: 0.704 | Val Loss: 0.7451 | Train F1: 0.1761| Val F1: 0.0530\n",
      "Epoch 250: | Train Loss: 0.703 | Val Loss: 0.7444 | Train F1: 0.2025| Val F1: 0.0554\n",
      "Epoch 300: | Train Loss: 0.701 | Val Loss: 0.7437 | Train F1: 0.2210| Val F1: 0.0556\n",
      "Epoch 350: | Train Loss: 0.700 | Val Loss: 0.7430 | Train F1: 0.2204| Val F1: 0.0602\n",
      "Epoch 400: | Train Loss: 0.699 | Val Loss: 0.7423 | Train F1: 0.2415| Val F1: 0.0603\n",
      "Epoch 450: | Train Loss: 0.698 | Val Loss: 0.7416 | Train F1: 0.2323| Val F1: 0.0556\n",
      "Epoch 500: | Train Loss: 0.696 | Val Loss: 0.7410 | Train F1: 0.2466| Val F1: 0.0557\n",
      "Epoch 550: | Train Loss: 0.696 | Val Loss: 0.7403 | Train F1: 0.2694| Val F1: 0.0558\n",
      "Epoch 600: | Train Loss: 0.694 | Val Loss: 0.7397 | Train F1: 0.2839| Val F1: 0.0558\n",
      "Epoch 650: | Train Loss: 0.693 | Val Loss: 0.7391 | Train F1: 0.2890| Val F1: 0.0627\n",
      "Epoch 700: | Train Loss: 0.692 | Val Loss: 0.7384 | Train F1: 0.2900| Val F1: 0.0604\n",
      "Epoch 750: | Train Loss: 0.691 | Val Loss: 0.7378 | Train F1: 0.3021| Val F1: 0.0533\n",
      "Epoch 800: | Train Loss: 0.691 | Val Loss: 0.7372 | Train F1: 0.3026| Val F1: 0.0533\n",
      "Epoch 850: | Train Loss: 0.689 | Val Loss: 0.7366 | Train F1: 0.3211| Val F1: 0.0509\n",
      "Epoch 900: | Train Loss: 0.687 | Val Loss: 0.7360 | Train F1: 0.3007| Val F1: 0.0462\n",
      "Epoch 950: | Train Loss: 0.687 | Val Loss: 0.7355 | Train F1: 0.3573| Val F1: 0.0506\n",
      "Epoch 1000: | Train Loss: 0.686 | Val Loss: 0.7349 | Train F1: 0.3593| Val F1: 0.0482\n",
      "Accuracy: 0.5574229691876751\n",
      "Precision: 0.35714285714285715\n",
      "Recall: 0.025839793281653745\n",
      "F1: 0.04819277108433735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb50a83f7414cd8bb0cdf7fbc5aa858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Accuracy: 0.5663865546218487\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ad3d7239b54e60bf9a68bec7a73a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Accuracy: 0.561344537815126\n",
      "Precision: 0.38461538461538464\n",
      "Recall: 0.01937984496124031\n",
      "F1: 0.03690036900369004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933d625768e9499ba5845272d4c2e9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.639 | Val Loss: 0.7095 | Train F1: 0.4743| Val F1: 0.0224\n",
      "Epoch 100: | Train Loss: 0.585 | Val Loss: 0.7054 | Train F1: 0.7595| Val F1: 0.0462\n",
      "Epoch 150: | Train Loss: 0.558 | Val Loss: 0.7016 | Train F1: 0.8236| Val F1: 0.0651\n",
      "Epoch 200: | Train Loss: 0.543 | Val Loss: 0.6995 | Train F1: 0.8712| Val F1: 0.0674\n",
      "Epoch 250: | Train Loss: 0.537 | Val Loss: 0.6985 | Train F1: 0.8690| Val F1: 0.0585\n",
      "Epoch 300: | Train Loss: 0.532 | Val Loss: 0.6979 | Train F1: 0.8865| Val F1: 0.0586\n",
      "Early stopping at epoch 308\n",
      "Accuracy: 0.5680672268907563\n",
      "Precision: 0.5319148936170213\n",
      "Recall: 0.03229974160206718\n",
      "F1: 0.06090133982947625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5e905fe16a45daa8cb4d263a4c66ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.704 | Val Loss: 0.7430 | Train F1: 0.0028| Val F1: 0.0000\n",
      "Epoch 100: | Train Loss: 0.696 | Val Loss: 0.7346 | Train F1: 0.0029| Val F1: 0.0000\n",
      "Epoch 150: | Train Loss: 0.689 | Val Loss: 0.7282 | Train F1: 0.0550| Val F1: 0.0000\n",
      "Epoch 200: | Train Loss: 0.681 | Val Loss: 0.7232 | Train F1: 0.1888| Val F1: 0.0000\n",
      "Epoch 250: | Train Loss: 0.674 | Val Loss: 0.7192 | Train F1: 0.2431| Val F1: 0.0026\n",
      "Epoch 300: | Train Loss: 0.665 | Val Loss: 0.7160 | Train F1: 0.3110| Val F1: 0.0077\n",
      "Epoch 350: | Train Loss: 0.659 | Val Loss: 0.7136 | Train F1: 0.3470| Val F1: 0.0178\n",
      "Epoch 400: | Train Loss: 0.653 | Val Loss: 0.7118 | Train F1: 0.3597| Val F1: 0.0227\n",
      "Epoch 450: | Train Loss: 0.646 | Val Loss: 0.7105 | Train F1: 0.4033| Val F1: 0.0226\n",
      "Epoch 500: | Train Loss: 0.640 | Val Loss: 0.7097 | Train F1: 0.4130| Val F1: 0.0224\n",
      "Epoch 550: | Train Loss: 0.635 | Val Loss: 0.7091 | Train F1: 0.4797| Val F1: 0.0248\n",
      "Epoch 600: | Train Loss: 0.629 | Val Loss: 0.7086 | Train F1: 0.5377| Val F1: 0.0248\n",
      "Epoch 650: | Train Loss: 0.623 | Val Loss: 0.7084 | Train F1: 0.5779| Val F1: 0.0321\n",
      "Epoch 700: | Train Loss: 0.617 | Val Loss: 0.7083 | Train F1: 0.6273| Val F1: 0.0418\n",
      "Early stopping at epoch 730\n",
      "Accuracy: 0.5647058823529412\n",
      "Precision: 0.4634146341463415\n",
      "Recall: 0.02454780361757106\n",
      "F1: 0.046625766871165646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950b2e1b836742e6a994b8234f57873b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Accuracy: 0.5663865546218487\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10dfae14dc2493d8ae770b6ede6cb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.556 | Val Loss: 0.6962 | Train F1: 0.8211| Val F1: 0.0467\n",
      "Early stopping at epoch 60\n",
      "Accuracy: 0.5658263305322129\n",
      "Precision: 0.49295774647887325\n",
      "Recall: 0.04521963824289406\n",
      "F1: 0.08284023668639054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06aad34bd7cc430b95cabd0d9bbba5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.663 | Val Loss: 0.7171 | Train F1: 0.3790| Val F1: 0.0201\n",
      "Epoch 100: | Train Loss: 0.618 | Val Loss: 0.7089 | Train F1: 0.6128| Val F1: 0.0343\n",
      "Epoch 150: | Train Loss: 0.588 | Val Loss: 0.7067 | Train F1: 0.7126| Val F1: 0.0574\n",
      "Epoch 200: | Train Loss: 0.568 | Val Loss: 0.7045 | Train F1: 0.7690| Val F1: 0.0643\n",
      "Epoch 250: | Train Loss: 0.555 | Val Loss: 0.7031 | Train F1: 0.7719| Val F1: 0.0760\n",
      "Epoch 300: | Train Loss: 0.544 | Val Loss: 0.7013 | Train F1: 0.8263| Val F1: 0.0858\n",
      "Epoch 350: | Train Loss: 0.537 | Val Loss: 0.6992 | Train F1: 0.8507| Val F1: 0.0887\n",
      "Early stopping at epoch 366\n",
      "Accuracy: 0.5725490196078431\n",
      "Precision: 0.5964912280701754\n",
      "Recall: 0.04392764857881137\n",
      "F1: 0.08182912154031288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d707db737440f19be3caf8f6694ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.712 | Val Loss: 0.7564 | Train F1: 0.4882| Val F1: 0.5369\n",
      "Epoch 100: | Train Loss: 0.706 | Val Loss: 0.7508 | Train F1: 0.3940| Val F1: 0.2885\n",
      "Epoch 150: | Train Loss: 0.701 | Val Loss: 0.7453 | Train F1: 0.2546| Val F1: 0.0560\n",
      "Epoch 200: | Train Loss: 0.696 | Val Loss: 0.7401 | Train F1: 0.1915| Val F1: 0.0153\n",
      "Epoch 250: | Train Loss: 0.691 | Val Loss: 0.7353 | Train F1: 0.1545| Val F1: 0.0026\n",
      "Epoch 300: | Train Loss: 0.686 | Val Loss: 0.7310 | Train F1: 0.1947| Val F1: 0.0026\n",
      "Epoch 350: | Train Loss: 0.680 | Val Loss: 0.7273 | Train F1: 0.2459| Val F1: 0.0026\n",
      "Epoch 400: | Train Loss: 0.675 | Val Loss: 0.7240 | Train F1: 0.2963| Val F1: 0.0026\n",
      "Epoch 450: | Train Loss: 0.670 | Val Loss: 0.7213 | Train F1: 0.3339| Val F1: 0.0026\n",
      "Epoch 500: | Train Loss: 0.664 | Val Loss: 0.7190 | Train F1: 0.3318| Val F1: 0.0153\n",
      "Epoch 550: | Train Loss: 0.659 | Val Loss: 0.7170 | Train F1: 0.3958| Val F1: 0.0152\n",
      "Epoch 600: | Train Loss: 0.655 | Val Loss: 0.7154 | Train F1: 0.4163| Val F1: 0.0202\n",
      "Epoch 650: | Train Loss: 0.650 | Val Loss: 0.7141 | Train F1: 0.4210| Val F1: 0.0226\n",
      "Epoch 700: | Train Loss: 0.646 | Val Loss: 0.7130 | Train F1: 0.4551| Val F1: 0.0200\n",
      "Epoch 750: | Train Loss: 0.641 | Val Loss: 0.7121 | Train F1: 0.4769| Val F1: 0.0225\n",
      "Epoch 800: | Train Loss: 0.637 | Val Loss: 0.7114 | Train F1: 0.5090| Val F1: 0.0249\n",
      "Epoch 850: | Train Loss: 0.633 | Val Loss: 0.7108 | Train F1: 0.5246| Val F1: 0.0273\n",
      "Epoch 900: | Train Loss: 0.630 | Val Loss: 0.7103 | Train F1: 0.5570| Val F1: 0.0322\n",
      "Epoch 950: | Train Loss: 0.625 | Val Loss: 0.7099 | Train F1: 0.5894| Val F1: 0.0321\n",
      "Epoch 1000: | Train Loss: 0.621 | Val Loss: 0.7096 | Train F1: 0.6017| Val F1: 0.0320\n",
      "Accuracy: 0.5596638655462185\n",
      "Precision: 0.34210526315789475\n",
      "Recall: 0.016795865633074936\n",
      "F1: 0.03201970443349754\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d321ba6b33c047e58256cb4862b0c19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Accuracy: 0.5624649859943978\n",
      "Precision: 0.3939393939393939\n",
      "Recall: 0.016795865633074936\n",
      "F1: 0.0322180916976456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2090d7f17b334eca86c09f837a111cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.559 | Val Loss: 0.7010 | Train F1: 0.7637| Val F1: 0.0675\n",
      "Early stopping at epoch 70\n",
      "Accuracy: 0.5647058823529412\n",
      "Precision: 0.4727272727272727\n",
      "Recall: 0.03359173126614987\n",
      "F1: 0.06272617611580217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfef2adb52334ce8aaf6dcbd60cf28dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.684 | Val Loss: 0.7302 | Train F1: 0.2430| Val F1: 0.0077\n",
      "Epoch 100: | Train Loss: 0.645 | Val Loss: 0.7139 | Train F1: 0.4911| Val F1: 0.0297\n",
      "Epoch 150: | Train Loss: 0.616 | Val Loss: 0.7097 | Train F1: 0.6477| Val F1: 0.0507\n",
      "Epoch 200: | Train Loss: 0.595 | Val Loss: 0.7075 | Train F1: 0.7050| Val F1: 0.0529\n",
      "Epoch 250: | Train Loss: 0.580 | Val Loss: 0.7054 | Train F1: 0.7264| Val F1: 0.0627\n",
      "Epoch 300: | Train Loss: 0.570 | Val Loss: 0.7039 | Train F1: 0.7442| Val F1: 0.0855\n",
      "Epoch 350: | Train Loss: 0.559 | Val Loss: 0.7021 | Train F1: 0.7907| Val F1: 0.0905\n",
      "Epoch 400: | Train Loss: 0.554 | Val Loss: 0.7008 | Train F1: 0.7774| Val F1: 0.0793\n",
      "Epoch 450: | Train Loss: 0.546 | Val Loss: 0.6996 | Train F1: 0.8269| Val F1: 0.0840\n",
      "Epoch 500: | Train Loss: 0.542 | Val Loss: 0.6990 | Train F1: 0.8156| Val F1: 0.0862\n",
      "Early stopping at epoch 526\n",
      "Accuracy: 0.5714285714285714\n",
      "Precision: 0.576271186440678\n",
      "Recall: 0.04392764857881137\n",
      "F1: 0.08163265306122448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb493b4ccf64d6ca7738ae79ee43286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.711 | Val Loss: 0.7547 | Train F1: 0.4055| Val F1: 0.2812\n",
      "Epoch 100: | Train Loss: 0.709 | Val Loss: 0.7519 | Train F1: 0.3573| Val F1: 0.1178\n",
      "Epoch 150: | Train Loss: 0.705 | Val Loss: 0.7490 | Train F1: 0.3312| Val F1: 0.0440\n",
      "Epoch 200: | Train Loss: 0.703 | Val Loss: 0.7461 | Train F1: 0.2599| Val F1: 0.0076\n",
      "Epoch 250: | Train Loss: 0.699 | Val Loss: 0.7432 | Train F1: 0.2552| Val F1: 0.0000\n",
      "Epoch 300: | Train Loss: 0.696 | Val Loss: 0.7402 | Train F1: 0.2806| Val F1: 0.0000\n",
      "Epoch 350: | Train Loss: 0.692 | Val Loss: 0.7373 | Train F1: 0.2341| Val F1: 0.0000\n",
      "Epoch 400: | Train Loss: 0.688 | Val Loss: 0.7346 | Train F1: 0.2195| Val F1: 0.0000\n",
      "Epoch 450: | Train Loss: 0.686 | Val Loss: 0.7319 | Train F1: 0.2620| Val F1: 0.0000\n",
      "Epoch 500: | Train Loss: 0.684 | Val Loss: 0.7295 | Train F1: 0.2561| Val F1: 0.0000\n",
      "Epoch 550: | Train Loss: 0.679 | Val Loss: 0.7271 | Train F1: 0.2827| Val F1: 0.0000\n",
      "Epoch 600: | Train Loss: 0.677 | Val Loss: 0.7250 | Train F1: 0.2903| Val F1: 0.0051\n",
      "Epoch 650: | Train Loss: 0.673 | Val Loss: 0.7230 | Train F1: 0.3205| Val F1: 0.0077\n",
      "Epoch 700: | Train Loss: 0.669 | Val Loss: 0.7212 | Train F1: 0.3428| Val F1: 0.0127\n",
      "Epoch 750: | Train Loss: 0.666 | Val Loss: 0.7195 | Train F1: 0.3772| Val F1: 0.0127\n",
      "Epoch 800: | Train Loss: 0.664 | Val Loss: 0.7181 | Train F1: 0.3943| Val F1: 0.0152\n",
      "Epoch 850: | Train Loss: 0.661 | Val Loss: 0.7168 | Train F1: 0.3985| Val F1: 0.0177\n",
      "Epoch 900: | Train Loss: 0.657 | Val Loss: 0.7155 | Train F1: 0.4353| Val F1: 0.0202\n",
      "Epoch 950: | Train Loss: 0.654 | Val Loss: 0.7145 | Train F1: 0.4366| Val F1: 0.0202\n",
      "Epoch 1000: | Train Loss: 0.651 | Val Loss: 0.7135 | Train F1: 0.4261| Val F1: 0.0202\n",
      "Accuracy: 0.5641456582633053\n",
      "Precision: 0.4\n",
      "Recall: 0.0103359173126615\n",
      "F1: 0.020151133501259445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6797c7cf3cf642c7936af21da2664e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Accuracy: 0.5658263305322129\n",
      "Precision: 0.49230769230769234\n",
      "Recall: 0.041343669250646\n",
      "F1: 0.07628128724672228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76dc33c2e864e6581193e685951484e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.578 | Val Loss: 0.7037 | Train F1: 0.7689| Val F1: 0.0698\n",
      "Epoch 100: | Train Loss: 0.552 | Val Loss: 0.6993 | Train F1: 0.7921| Val F1: 0.0700\n",
      "Epoch 150: | Train Loss: 0.533 | Val Loss: 0.6991 | Train F1: 0.8892| Val F1: 0.0763\n",
      "Early stopping at epoch 153\n",
      "Accuracy: 0.5658263305322129\n",
      "Precision: 0.49019607843137253\n",
      "Recall: 0.03229974160206718\n",
      "F1: 0.06060606060606061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df72871534454be4945f7b93a1abedeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.697 | Val Loss: 0.7404 | Train F1: 0.2584| Val F1: 0.0127\n",
      "Epoch 100: | Train Loss: 0.673 | Val Loss: 0.7242 | Train F1: 0.3558| Val F1: 0.0225\n",
      "Epoch 150: | Train Loss: 0.653 | Val Loss: 0.7152 | Train F1: 0.4530| Val F1: 0.0369\n",
      "Epoch 200: | Train Loss: 0.635 | Val Loss: 0.7113 | Train F1: 0.5453| Val F1: 0.0461\n",
      "Epoch 250: | Train Loss: 0.621 | Val Loss: 0.7096 | Train F1: 0.6083| Val F1: 0.0483\n",
      "Epoch 300: | Train Loss: 0.609 | Val Loss: 0.7086 | Train F1: 0.6745| Val F1: 0.0782\n",
      "Epoch 350: | Train Loss: 0.598 | Val Loss: 0.7074 | Train F1: 0.6863| Val F1: 0.0802\n",
      "Epoch 400: | Train Loss: 0.588 | Val Loss: 0.7064 | Train F1: 0.7057| Val F1: 0.0799\n",
      "Epoch 450: | Train Loss: 0.579 | Val Loss: 0.7059 | Train F1: 0.7251| Val F1: 0.0820\n",
      "Early stopping at epoch 454\n",
      "Accuracy: 0.5607843137254902\n",
      "Precision: 0.4375\n",
      "Recall: 0.04521963824289406\n",
      "F1: 0.08196721311475409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab14cc00f9e5424ebe365157d5104729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.709 | Val Loss: 0.7491 | Train F1: 0.0685| Val F1: 0.0000\n",
      "Epoch 100: | Train Loss: 0.708 | Val Loss: 0.7479 | Train F1: 0.0543| Val F1: 0.0000\n",
      "Epoch 150: | Train Loss: 0.707 | Val Loss: 0.7467 | Train F1: 0.0439| Val F1: 0.0000\n",
      "Epoch 200: | Train Loss: 0.705 | Val Loss: 0.7454 | Train F1: 0.0450| Val F1: 0.0000\n",
      "Epoch 250: | Train Loss: 0.704 | Val Loss: 0.7440 | Train F1: 0.0417| Val F1: 0.0000\n",
      "Epoch 300: | Train Loss: 0.702 | Val Loss: 0.7426 | Train F1: 0.0660| Val F1: 0.0000\n",
      "Epoch 350: | Train Loss: 0.700 | Val Loss: 0.7411 | Train F1: 0.0377| Val F1: 0.0000\n",
      "Epoch 400: | Train Loss: 0.698 | Val Loss: 0.7396 | Train F1: 0.0313| Val F1: 0.0000\n",
      "Epoch 450: | Train Loss: 0.697 | Val Loss: 0.7381 | Train F1: 0.0537| Val F1: 0.0000\n",
      "Epoch 500: | Train Loss: 0.695 | Val Loss: 0.7365 | Train F1: 0.0450| Val F1: 0.0000\n",
      "Epoch 550: | Train Loss: 0.692 | Val Loss: 0.7350 | Train F1: 0.0622| Val F1: 0.0000\n",
      "Epoch 600: | Train Loss: 0.690 | Val Loss: 0.7334 | Train F1: 0.0441| Val F1: 0.0000\n",
      "Epoch 650: | Train Loss: 0.688 | Val Loss: 0.7318 | Train F1: 0.0791| Val F1: 0.0000\n",
      "Epoch 700: | Train Loss: 0.686 | Val Loss: 0.7302 | Train F1: 0.1050| Val F1: 0.0000\n",
      "Epoch 750: | Train Loss: 0.685 | Val Loss: 0.7287 | Train F1: 0.1293| Val F1: 0.0000\n",
      "Epoch 800: | Train Loss: 0.681 | Val Loss: 0.7272 | Train F1: 0.1430| Val F1: 0.0000\n",
      "Epoch 850: | Train Loss: 0.680 | Val Loss: 0.7256 | Train F1: 0.1301| Val F1: 0.0000\n",
      "Epoch 900: | Train Loss: 0.678 | Val Loss: 0.7242 | Train F1: 0.1697| Val F1: 0.0000\n",
      "Epoch 950: | Train Loss: 0.675 | Val Loss: 0.7227 | Train F1: 0.1764| Val F1: 0.0000\n",
      "Epoch 1000: | Train Loss: 0.674 | Val Loss: 0.7214 | Train F1: 0.1782| Val F1: 0.0000\n",
      "Accuracy: 0.5658263305322129\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e9808c50154f808abac3de176b937e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24\n",
      "Accuracy: 0.5658263305322129\n",
      "Precision: 0.49333333333333335\n",
      "Recall: 0.04780361757105943\n",
      "F1: 0.08716136631330977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61496aaa0260496895b52edf63bd9b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.619 | Val Loss: 0.7054 | Train F1: 0.5603| Val F1: 0.0508\n",
      "Epoch 100: | Train Loss: 0.579 | Val Loss: 0.7008 | Train F1: 0.7254| Val F1: 0.0760\n",
      "Epoch 150: | Train Loss: 0.559 | Val Loss: 0.6992 | Train F1: 0.8091| Val F1: 0.0948\n",
      "Early stopping at epoch 175\n",
      "Accuracy: 0.5708683473389355\n",
      "Precision: 0.5625\n",
      "Recall: 0.046511627906976744\n",
      "F1: 0.08591885441527446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2396d0f91a7e4fd6881c6a586b601b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.719 | Val Loss: 0.7684 | Train F1: 0.5528| Val F1: 0.6049\n",
      "Epoch 100: | Train Loss: 0.712 | Val Loss: 0.7611 | Train F1: 0.5003| Val F1: 0.5728\n",
      "Epoch 150: | Train Loss: 0.702 | Val Loss: 0.7519 | Train F1: 0.4426| Val F1: 0.3463\n",
      "Epoch 200: | Train Loss: 0.692 | Val Loss: 0.7425 | Train F1: 0.4245| Val F1: 0.2100\n",
      "Epoch 250: | Train Loss: 0.681 | Val Loss: 0.7342 | Train F1: 0.4130| Val F1: 0.1564\n",
      "Epoch 300: | Train Loss: 0.670 | Val Loss: 0.7284 | Train F1: 0.4195| Val F1: 0.1384\n",
      "Epoch 350: | Train Loss: 0.661 | Val Loss: 0.7246 | Train F1: 0.4382| Val F1: 0.1326\n",
      "Epoch 400: | Train Loss: 0.653 | Val Loss: 0.7223 | Train F1: 0.4854| Val F1: 0.1351\n",
      "Epoch 450: | Train Loss: 0.646 | Val Loss: 0.7210 | Train F1: 0.4751| Val F1: 0.1522\n",
      "Epoch 500: | Train Loss: 0.638 | Val Loss: 0.7196 | Train F1: 0.5201| Val F1: 0.1660\n",
      "Epoch 550: | Train Loss: 0.631 | Val Loss: 0.7186 | Train F1: 0.5423| Val F1: 0.1763\n",
      "Epoch 600: | Train Loss: 0.624 | Val Loss: 0.7175 | Train F1: 0.5688| Val F1: 0.1726\n",
      "Epoch 650: | Train Loss: 0.619 | Val Loss: 0.7167 | Train F1: 0.5625| Val F1: 0.1719\n",
      "Epoch 700: | Train Loss: 0.613 | Val Loss: 0.7157 | Train F1: 0.5750| Val F1: 0.1624\n",
      "Epoch 750: | Train Loss: 0.609 | Val Loss: 0.7146 | Train F1: 0.5908| Val F1: 0.1587\n",
      "Epoch 800: | Train Loss: 0.605 | Val Loss: 0.7136 | Train F1: 0.5769| Val F1: 0.1612\n",
      "Epoch 850: | Train Loss: 0.601 | Val Loss: 0.7127 | Train F1: 0.5949| Val F1: 0.1633\n",
      "Early stopping at epoch 892\n",
      "Accuracy: 0.5591036414565826\n",
      "Precision: 0.46107784431137727\n",
      "Recall: 0.09948320413436693\n",
      "F1: 0.1636556854410202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d46fabdf4b41f3aebea75005336566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050: | Train Loss: 0.712 | Val Loss: 0.7518 | Train F1: 0.0377| Val F1: 0.0076\n",
      "Epoch 100: | Train Loss: 0.711 | Val Loss: 0.7515 | Train F1: 0.0404| Val F1: 0.0026\n",
      "Epoch 150: | Train Loss: 0.711 | Val Loss: 0.7511 | Train F1: 0.0307| Val F1: 0.0000\n",
      "Epoch 200: | Train Loss: 0.711 | Val Loss: 0.7508 | Train F1: 0.0661| Val F1: 0.0000\n",
      "Epoch 250: | Train Loss: 0.710 | Val Loss: 0.7506 | Train F1: 0.0547| Val F1: 0.0000\n",
      "Epoch 300: | Train Loss: 0.710 | Val Loss: 0.7503 | Train F1: 0.0684| Val F1: 0.0000\n",
      "Epoch 350: | Train Loss: 0.710 | Val Loss: 0.7501 | Train F1: 0.0406| Val F1: 0.0000\n",
      "Epoch 400: | Train Loss: 0.709 | Val Loss: 0.7498 | Train F1: 0.0699| Val F1: 0.0000\n",
      "Epoch 450: | Train Loss: 0.709 | Val Loss: 0.7495 | Train F1: 0.0760| Val F1: 0.0000\n",
      "Epoch 500: | Train Loss: 0.709 | Val Loss: 0.7492 | Train F1: 0.0891| Val F1: 0.0000\n",
      "Epoch 550: | Train Loss: 0.708 | Val Loss: 0.7489 | Train F1: 0.0947| Val F1: 0.0000\n",
      "Epoch 600: | Train Loss: 0.708 | Val Loss: 0.7486 | Train F1: 0.0945| Val F1: 0.0000\n",
      "Epoch 650: | Train Loss: 0.707 | Val Loss: 0.7483 | Train F1: 0.1440| Val F1: 0.0000\n",
      "Epoch 700: | Train Loss: 0.707 | Val Loss: 0.7480 | Train F1: 0.0947| Val F1: 0.0000\n",
      "Epoch 750: | Train Loss: 0.706 | Val Loss: 0.7477 | Train F1: 0.1035| Val F1: 0.0000\n",
      "Epoch 800: | Train Loss: 0.706 | Val Loss: 0.7474 | Train F1: 0.0893| Val F1: 0.0051\n",
      "Epoch 850: | Train Loss: 0.706 | Val Loss: 0.7471 | Train F1: 0.1742| Val F1: 0.0077\n",
      "Epoch 900: | Train Loss: 0.705 | Val Loss: 0.7468 | Train F1: 0.1402| Val F1: 0.0077\n",
      "Epoch 950: | Train Loss: 0.704 | Val Loss: 0.7464 | Train F1: 0.1167| Val F1: 0.0103\n",
      "Epoch 1000: | Train Loss: 0.704 | Val Loss: 0.7461 | Train F1: 0.1727| Val F1: 0.0128\n",
      "Accuracy: 0.5675070028011204\n",
      "Precision: 0.625\n",
      "Recall: 0.006459948320413436\n",
      "F1: 0.01278772378516624\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "K = 1\n",
    "\n",
    "# Define your hyperparameters\n",
    "hidden_layers = [1, 2]\n",
    "hidden_layer_max_sizes = [256, 128, 64, 32, 16]\n",
    "lrs = [0.01, 0.001, 0.0001, 0.00001]\n",
    "patience = [10]\n",
    "\n",
    "if K > 1:\n",
    "    k_fold = KFold(n_splits=K)  # Specify K as the number of folds\n",
    "\n",
    "results = []\n",
    "\n",
    "for h_layers, h_size, lr, pat in itertools.product(hidden_layers, hidden_layer_max_sizes, lrs, patience):\n",
    "\n",
    "    hidden_layers_struct = get_layers(h_layers,h_size)\n",
    "    \n",
    "    fold_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F1': []}\n",
    "\n",
    "    if K == 1:\n",
    "        dim = int(reduced_X_train.shape[0])\n",
    "        dim_thres = int(dim*0.5)\n",
    "        fold_generator = [(np.arange(0,dim_thres),np.arange(dim_thres,dim))]\n",
    "    else:\n",
    "        fold_generator = k_fold.split(reduced_X_train)\n",
    "        \n",
    "    for train_index, val_index in fold_generator:\n",
    "        # Split data into train and validation set for this fold\n",
    "        X_train_fold, X_val_fold = reduced_X_train[train_index], reduced_X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Create datasets and model\n",
    "        train_loader, _, val_dataset = create_datasets(X_train_fold, y_train_fold, X_test, y_test, X_val_fold, y_val_fold, val=True, batch_size=320)\n",
    "        model = NeuralNetwork(input_size, hidden_layers_struct, output_size, lr, device=device, hidden_activation=hidden_activation, output_activation=output_activation, criterion=criterion)\n",
    "\n",
    "        # Train the model\n",
    "        train_nn(model, train_loader, val_dataset, num_epochs=num_epochs, skip=50, patience=pat)\n",
    "\n",
    "        # Evaluate the model on validation set for this fold\n",
    "        y_pred = predict_nn(model, val_dataset)\n",
    "        accuracy, precision, recall, f1 = eval_predict_nn(y_val_fold, y_pred)\n",
    "\n",
    "        # Store metrics for this fold\n",
    "        fold_metrics['Accuracy'].append(accuracy)\n",
    "        fold_metrics['Precision'].append(precision)\n",
    "        fold_metrics['Recall'].append(recall)\n",
    "        fold_metrics['F1'].append(f1)\n",
    "\n",
    "    # Calculate mean metrics across all folds\n",
    "    mean_accuracy = np.mean(fold_metrics['Accuracy'])\n",
    "    mean_precision = np.mean(fold_metrics['Precision'])\n",
    "    mean_recall = np.mean(fold_metrics['Recall'])\n",
    "    mean_f1 = np.mean(fold_metrics['F1'])\n",
    "\n",
    "    # Store hyperparameters and mean metrics in results list\n",
    "    results.append({\n",
    "        'Hidden Layers': h_layers,\n",
    "        'Hidden Layer Size': h_size,\n",
    "        'Learning Rate': lr,\n",
    "        'Patience': pat,\n",
    "        'Mean Accuracy': mean_accuracy,\n",
    "        'Mean Precision': mean_precision,\n",
    "        'Mean Recall': mean_recall,\n",
    "        'Mean F1': mean_f1\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('new_model_results_no_CV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb4f3168-a390-45ed-913f-3c1b0f8b859c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Mean F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.921825</td>\n",
       "      <td>0.115083</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.078909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.923785</td>\n",
       "      <td>0.157987</td>\n",
       "      <td>0.081296</td>\n",
       "      <td>0.105608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885690</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>0.136685</td>\n",
       "      <td>0.110159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.875303</td>\n",
       "      <td>0.097406</td>\n",
       "      <td>0.130779</td>\n",
       "      <td>0.104775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.915101</td>\n",
       "      <td>0.093136</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.078036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.916782</td>\n",
       "      <td>0.111228</td>\n",
       "      <td>0.076174</td>\n",
       "      <td>0.087632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.879222</td>\n",
       "      <td>0.119208</td>\n",
       "      <td>0.151701</td>\n",
       "      <td>0.126239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.868579</td>\n",
       "      <td>0.088567</td>\n",
       "      <td>0.135901</td>\n",
       "      <td>0.105568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.909777</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.077041</td>\n",
       "      <td>0.077174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.897732</td>\n",
       "      <td>0.102269</td>\n",
       "      <td>0.098971</td>\n",
       "      <td>0.092541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.880076</td>\n",
       "      <td>0.099541</td>\n",
       "      <td>0.142172</td>\n",
       "      <td>0.116442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.878953</td>\n",
       "      <td>0.097755</td>\n",
       "      <td>0.139796</td>\n",
       "      <td>0.114276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.905575</td>\n",
       "      <td>0.086870</td>\n",
       "      <td>0.081803</td>\n",
       "      <td>0.081898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.896052</td>\n",
       "      <td>0.127580</td>\n",
       "      <td>0.138277</td>\n",
       "      <td>0.130270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.884285</td>\n",
       "      <td>0.114753</td>\n",
       "      <td>0.154077</td>\n",
       "      <td>0.126163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.889889</td>\n",
       "      <td>0.126907</td>\n",
       "      <td>0.165475</td>\n",
       "      <td>0.138730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.943399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919304</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.878665</td>\n",
       "      <td>0.126250</td>\n",
       "      <td>0.137551</td>\n",
       "      <td>0.116102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.874465</td>\n",
       "      <td>0.098002</td>\n",
       "      <td>0.140434</td>\n",
       "      <td>0.107835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.943399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.912858</td>\n",
       "      <td>0.084281</td>\n",
       "      <td>0.056626</td>\n",
       "      <td>0.066308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.887910</td>\n",
       "      <td>0.117473</td>\n",
       "      <td>0.137541</td>\n",
       "      <td>0.119208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.886809</td>\n",
       "      <td>0.087417</td>\n",
       "      <td>0.113758</td>\n",
       "      <td>0.091531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.898296</td>\n",
       "      <td>0.072807</td>\n",
       "      <td>0.085818</td>\n",
       "      <td>0.067275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.904736</td>\n",
       "      <td>0.113732</td>\n",
       "      <td>0.102725</td>\n",
       "      <td>0.101472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908936</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.115131</td>\n",
       "      <td>0.110916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.910339</td>\n",
       "      <td>0.109639</td>\n",
       "      <td>0.089442</td>\n",
       "      <td>0.097564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919304</td>\n",
       "      <td>0.105740</td>\n",
       "      <td>0.064635</td>\n",
       "      <td>0.076394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.912856</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.113110</td>\n",
       "      <td>0.123253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.907256</td>\n",
       "      <td>0.095565</td>\n",
       "      <td>0.094716</td>\n",
       "      <td>0.092918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.887649</td>\n",
       "      <td>0.101929</td>\n",
       "      <td>0.138935</td>\n",
       "      <td>0.111273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hidden Layers  Hidden Layer Size  Learning Rate  Patience  Mean Accuracy  \\\n",
       "0               1                256         0.0100        10       0.921825   \n",
       "1               1                256         0.0010        10       0.923785   \n",
       "2               1                256         0.0001        10       0.885690   \n",
       "3               1                256         0.0001        10       0.875303   \n",
       "4               1                128         0.0100        10       0.915101   \n",
       "5               1                128         0.0010        10       0.916782   \n",
       "6               1                128         0.0001        10       0.879222   \n",
       "7               1                128         0.0001        10       0.868579   \n",
       "8               1                 64         0.0100        10       0.909777   \n",
       "9               1                 64         0.0010        10       0.897732   \n",
       "10              1                 64         0.0001        10       0.880076   \n",
       "11              1                 64         0.0001        10       0.878953   \n",
       "12              1                 32         0.0100        10       0.905575   \n",
       "13              1                 32         0.0010        10       0.896052   \n",
       "14              1                 32         0.0001        10       0.884285   \n",
       "15              1                 32         0.0001        10       0.889889   \n",
       "16              2                256         0.0100        10       0.943399   \n",
       "17              2                256         0.0010        10       0.919304   \n",
       "18              2                256         0.0001        10       0.878665   \n",
       "19              2                256         0.0001        10       0.874465   \n",
       "20              2                128         0.0100        10       0.943399   \n",
       "21              2                128         0.0010        10       0.912858   \n",
       "22              2                128         0.0001        10       0.887910   \n",
       "23              2                128         0.0001        10       0.886809   \n",
       "24              2                 64         0.0100        10       0.898296   \n",
       "25              2                 64         0.0010        10       0.904736   \n",
       "26              2                 64         0.0001        10       0.908936   \n",
       "27              2                 64         0.0001        10       0.910339   \n",
       "28              2                 32         0.0100        10       0.919304   \n",
       "29              2                 32         0.0010        10       0.912856   \n",
       "30              2                 32         0.0001        10       0.907256   \n",
       "31              2                 32         0.0001        10       0.887649   \n",
       "\n",
       "    Mean Precision  Mean Recall   Mean F1  \n",
       "0         0.115083     0.061747  0.078909  \n",
       "1         0.157987     0.081296  0.105608  \n",
       "2         0.108361     0.136685  0.110159  \n",
       "3         0.097406     0.130779  0.104775  \n",
       "4         0.093136     0.071778  0.078036  \n",
       "5         0.111228     0.076174  0.087632  \n",
       "6         0.119208     0.151701  0.126239  \n",
       "7         0.088567     0.135901  0.105568  \n",
       "8         0.085714     0.077041  0.077174  \n",
       "9         0.102269     0.098971  0.092541  \n",
       "10        0.099541     0.142172  0.116442  \n",
       "11        0.097755     0.139796  0.114276  \n",
       "12        0.086870     0.081803  0.081898  \n",
       "13        0.127580     0.138277  0.130270  \n",
       "14        0.114753     0.154077  0.126163  \n",
       "15        0.126907     0.165475  0.138730  \n",
       "16        0.000000     0.000000  0.000000  \n",
       "17        0.092700     0.059007  0.069800  \n",
       "18        0.126250     0.137551  0.116102  \n",
       "19        0.098002     0.140434  0.107835  \n",
       "20        0.000000     0.000000  0.000000  \n",
       "21        0.084281     0.056626  0.066308  \n",
       "22        0.117473     0.137541  0.119208  \n",
       "23        0.087417     0.113758  0.091531  \n",
       "24        0.072807     0.085818  0.067275  \n",
       "25        0.113732     0.102725  0.101472  \n",
       "26        0.118811     0.115131  0.110916  \n",
       "27        0.109639     0.089442  0.097564  \n",
       "28        0.105740     0.064635  0.076394  \n",
       "29        0.142979     0.113110  0.123253  \n",
       "30        0.095565     0.094716  0.092918  \n",
       "31        0.101929     0.138935  0.111273  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582c0cf3-02f3-403b-ab28-bf3d143eeca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Mean F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.790388</td>\n",
       "      <td>0.650217</td>\n",
       "      <td>0.842482</td>\n",
       "      <td>0.639973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layers  Hidden Layer Size  Learning Rate  Patience  Mean Accuracy  \\\n",
       "0              1                256           0.10       100       0.500000   \n",
       "1              1                256           0.01       100       0.790388   \n",
       "\n",
       "   Mean Precision  Mean Recall   Mean F1  \n",
       "0        0.000000     0.000000  0.000000  \n",
       "1        0.650217     0.842482  0.639973  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
